import os
import json
import logging
import time
import shutil
from pathlib import Path
from typing import Dict, List, Optional

from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeDocumentRequest

from config import Config

# Nastaven√≠ loggingu
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AzureOCRClient:
    """Klient pro Azure Document Intelligence API"""
    
    def __init__(self, config: Config = None):
        """
        Inicializace Azure OCR klienta
        
        Args:
            config: Konfigurace (pokud nen√≠ zad√°na, pou≈æije se v√Ωchoz√≠)
        """
        if config is None:
            config = Config
            
        self.config = config
        self.endpoint = config.AZURE_ENDPOINT
        self.key = config.AZURE_KEY
        self.model_id = config.MODEL_ID
        
        # Vytvo≈ôen√≠ klienta
        self.client = DocumentIntelligenceClient(
            endpoint=self.endpoint,
            credential=AzureKeyCredential(self.key)
        )
        
        logger.info(f"Azure OCR klient inicializov√°n s modelem: {self.model_id}")
    
    def analyze_document_from_file(self, file_path: str) -> Optional[Dict]:
        """
        Analyzuje dokument ze souboru
        
        Args:
            file_path: Cesta k souboru
            
        Returns:
            Dict s v√Ωsledky anal√Ωzy nebo None p≈ôi chybƒõ
        """
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                logger.error(f"Soubor neexistuje: {file_path}")
                return None
                
            logger.info(f"Analyzuji dokument: {file_path.name}")
            
            # Otev≈ôen√≠ a odesl√°n√≠ souboru
            with open(file_path, "rb") as file:
                poller = self.client.begin_analyze_document(
                    model_id=self.model_id,
                    body=file,
                    content_type="application/octet-stream"
                )
                
            result = poller.result()
            logger.info(f"Anal√Ωza dokonƒçena pro: {file_path.name}")
            
            return self._process_result(result, file_path.name)
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi anal√Ωze {file_path}: {str(e)}")
            return None
    
    def analyze_document_from_url(self, document_url: str) -> Optional[Dict]:
        """
        Analyzuje dokument z URL
        
        Args:
            document_url: URL dokumentu
            
        Returns:
            Dict s v√Ωsledky anal√Ωzy nebo None p≈ôi chybƒõ
        """
        try:
            logger.info(f"Analyzuji dokument z URL: {document_url}")
            
            poller = self.client.begin_analyze_document(
                self.model_id,
                AnalyzeDocumentRequest(url_source=document_url)
            )
            
            result = poller.result()
            logger.info(f"Anal√Ωza z URL dokonƒçena")
            
            return self._process_result(result, document_url)
            
        except Exception as e:
            logger.error(f"Chyba p≈ôi anal√Ωze URL {document_url}: {str(e)}")
            return None
    
    def _process_result(self, result, source_name: str) -> Dict:
        """
        Zpracuje v√Ωsledek z Azure API do strukturovan√©ho form√°tu
        
        Args:
            result: V√Ωsledek z Azure API
            source_name: N√°zev zdroje (soubor/URL)
            
        Returns:
            Strukturovan√Ω slovn√≠k s v√Ωsledky
        """
        processed_result = {
            "source_file": source_name,
            "status": "success",
            "model_id": result.model_id,
            "api_version": result.api_version,
            "extracted_fields": {},
            "raw_content": result.content if hasattr(result, 'content') else "",
            "confidence_scores": {},
            "document_count": len(result.documents) if result.documents else 0
        }
        
        # Zpracov√°n√≠ extrahovan√Ωch pol√≠ z dokument≈Ø
        if result.documents:
            for idx, document in enumerate(result.documents):
                logger.info(f"Zpracov√°v√°m dokument #{idx + 1}, typ: {document.doc_type}, confidence: {document.confidence}")
                
                # Extrakce pol√≠
                if document.fields:
                    for field_name, field in list(document.fields.items()):
                        if field.content:
                            processed_result["extracted_fields"][field_name] = field.content
                            processed_result["confidence_scores"][field_name] = field.confidence
                            
                            logger.info(f"Pole '{field_name}': '{field.content}' (confidence: {field.confidence:.2%})")
        
        return processed_result
    
    def extract_key_fields(self, analysis_result: Dict) -> Dict:
        """
        Extrahuje kl√≠ƒçov√© informace ze z√°ruƒçn√≠ho listu
        
        Args:
            analysis_result: V√Ωsledek anal√Ωzy
            
        Returns:
            Dict s kl√≠ƒçov√Ωmi poli
        """
        fields = analysis_result.get("extracted_fields", {})
        
        # Mapov√°n√≠ pol√≠ na standardn√≠ n√°zvy
        key_fields = {
            "jmeno_zakaznika": fields.get("kupuj√≠c√≠ kotle jm√©no", ""),
            "adresa_zakaznika": fields.get("adresa z√°kazn√≠ka", "") or fields.get("adresa z√°kazn√≠ka doplneni", ""),
            "datum_instalace": fields.get("datum uveden√≠ do provozu", ""),
            "typ_kotle": fields.get("Typ kotle", ""),
            "vyrobni_cislo": fields.get("v√Ωrobn√≠ ƒç√≠slo kotle", ""),
            "prodejce": fields.get("prodejce kotle", ""),
            "adresa_prodejce": fields.get("adresa prodejce", ""),
            "regulators": fields.get("regul√°tor", ""),
            "cislo_opravneni": fields.get("ƒç√≠slo opr√°vnƒõn√≠", "")
        }
        
        # P≈ôid√°n√≠ confidence scores
        confidence_scores = analysis_result.get("confidence_scores", {})
        for field_name in list(key_fields.keys()):
            # Najdi odpov√≠daj√≠c√≠ confidence score
            for original_field, confidence in confidence_scores.items():
                if any(keyword in original_field.lower() for keyword in self._get_field_keywords(field_name)):
                    key_fields[f"{field_name}_confidence"] = confidence
                    break
        
        return key_fields
    
    def _get_field_keywords(self, field_name: str) -> List[str]:
        """Vr√°t√≠ kl√≠ƒçov√° slova pro mapov√°n√≠ pol√≠"""
        keywords_map = {
            "jmeno_zakaznika": ["kupuj√≠c√≠", "jm√©no"],
            "adresa_zakaznika": ["adresa z√°kazn√≠ka", "adresa"],
            "datum_instalace": ["datum", "uveden√≠", "provozu"],
            "typ_kotle": ["typ", "kotle"],
            "vyrobni_cislo": ["v√Ωrobn√≠", "ƒç√≠slo"],
            "prodejce": ["prodejce"],
            "adresa_prodejce": ["adresa prodejce"],
            "regulators": ["regul√°tor"],
            "cislo_opravneni": ["opr√°vnƒõn√≠"]
        }
        return keywords_map.get(field_name, [field_name])
    
    def process_directory(self, input_dir: str, output_dir: str) -> List[Dict]:
        """
        Zpracuje v≈°echny dokumenty ve slo≈æce
        
        Args:
            input_dir: Vstupn√≠ slo≈æka s dokumenty
            output_dir: V√Ωstupn√≠ slo≈æka pro JSON v√Ωsledky
            
        Returns:
            Seznam v√Ωsledk≈Ø anal√Ωzy
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        results = []
        supported_formats = {'.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp'}
        
        # Vytvo≈ôen√≠ processed slo≈æky
        processed_path = Path("data/processed")
        processed_path.mkdir(parents=True, exist_ok=True)
        
        for file_path in input_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_formats:
                # Anal√Ωza dokumentu
                result = self.analyze_document_from_file(str(file_path))
                
                if result:
                    # Extrakce kl√≠ƒçov√Ωch pol√≠
                    key_fields = self.extract_key_fields(result)
                    result["key_fields"] = key_fields
                    
                    # Ulo≈æen√≠ v√Ωsledku do JSON
                    output_file = output_path / f"{file_path.stem}_analysis.json"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"V√Ωsledek ulo≈æen: {output_file}")
                    
                    # üîÑ P≈òESUN ZPRACOVAN√âHO SOUBORU
                    try:
                        processed_file = processed_path / file_path.name
                        shutil.move(str(file_path), str(processed_file))
                        logger.info(f"‚úÖ Soubor p≈ôesunut: {file_path.name} ‚Üí data/processed/")
                        result["moved_to_processed"] = True
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Chyba p≈ôesunu souboru {file_path.name}: {e}")
                        result["moved_to_processed"] = False
                    
                else:
                    # Z√°znam ne√∫spƒõ≈°n√© anal√Ωzy
                    result = {
                        "source_file": file_path.name,
                        "status": "failed",
                        "error": "Anal√Ωza se nezda≈ôila",
                        "moved_to_processed": False
                    }
                
                results.append(result)
                
                # P≈ôid√°me pauzu mezi po≈æadavky aby nedo≈°lo k rate limitu
                time.sleep(2)
        
        logger.info(f"Zpracov√°no {len(results)} soubor≈Ø")
        return results

# Uk√°zkov√© pou≈æit√≠
if __name__ == "__main__":
    try:
        # Test konfigurace
        Config.validate_azure_config()
        
        # Vytvo≈ôen√≠ klienta
        ocr_client = AzureOCRClient()
        
        # Test na zpracovan√Ωch souborech
        input_folder = "data/input"
        output_folder = "data/output"
        
        if os.path.exists(input_folder):
            results = ocr_client.process_directory(input_folder, output_folder)
            
            print(f"\n=== V√ùSLEDKY ANAL√ùZY ===")
            print(f"Zpracov√°no celkem: {len(results)} soubor≈Ø")
            
            success_count = sum(1 for r in results if r.get('status') == 'success')
            failed_count = len(results) - success_count
            
            print(f"√öspƒõ≈°n√Ωch: {success_count}")
            print(f"Ne√∫spƒõ≈°n√Ωch: {failed_count}")
            if len(results) > 0:
                print(f"√öspƒõ≈°nost: {success_count/len(results)*100:.1f}%")
            else:
                print("√öspƒõ≈°nost: 0% (≈æ√°dn√© soubory nenalezeny)")
            
            # Uk√°zka extrahovan√Ωch dat
            for result in results[:3]:  # Zobraz prvn√≠ 3
                if result.get('status') == 'success':
                    print(f"\n--- {result['source_file']} ---")
                    key_fields = result.get('key_fields', {})
                    for field, value in key_fields.items():
                        if value and not field.endswith('_confidence'):
                            print(f"  {field}: {value}")
        else:
            print(f"Slo≈æka {input_folder} neexistuje")
            print("Nejd≈ô√≠v spus≈•te image_processor.py")
            
    except Exception as e:
        print(f"Chyba: {str(e)}")
        print("Zkontrolujte konfiguraci Azure credentials v config.py") 