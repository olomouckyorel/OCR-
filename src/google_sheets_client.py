import logging
import json
import csv
from datetime import datetime
from pathlib import Path
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Konfigurace logov√°n√≠
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GoogleSheetsClient:
    def __init__(self, credentials_file='google-credentials.json'):
        """
        Inicializace Google Sheets klienta
        
        Args:
            credentials_file: Cesta k JSON souboru s Service Account kl√≠ƒçi
        """
        self.credentials_file = credentials_file
        self.service = None
        self.spreadsheet_id = None
        self.processed_files_db = Path("processed_files.txt")
        self.duplicates_log = Path("duplicates_log.txt")
        
        # Scope pro Google Sheets API
        self.scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        
        self._authenticate()
        self._load_processed_files()
    
    def _authenticate(self):
        """Autentizace p≈ôes Service Account"""
        try:
            if not Path(self.credentials_file).exists():
                logger.error(f"Soubor s credentials nenalezen: {self.credentials_file}")
                logger.info("Vytvo≈ôte Service Account v Google Cloud Console a st√°hnƒõte JSON kl√≠ƒç")
                return False
            
            credentials = Credentials.from_service_account_file(
                self.credentials_file, 
                scopes=self.scopes
            )
            
            self.service = build('sheets', 'v4', credentials=credentials)
            logger.info("‚úÖ Google Sheets API p≈ôipojeno")
            return True
            
        except Exception as error:
            logger.error(f"‚ùå Chyba autentizace: {error}")
            return False
    
    def _load_processed_files(self):
        """Naƒçte seznam u≈æ zpracovan√Ωch soubor≈Ø"""
        self.processed_files = set()
        
        if self.processed_files_db.exists():
            try:
                with open(self.processed_files_db, 'r', encoding='utf-8') as f:
                    for line in f:
                        filename = line.strip()
                        if filename:
                            self.processed_files.add(filename)
                logger.info(f"üìã Naƒçteno {len(self.processed_files)} u≈æ zpracovan√Ωch soubor≈Ø")
            except Exception as e:
                logger.warning(f"Chyba ƒçten√≠ datab√°ze: {e}")
        else:
            logger.info("üìã Datab√°ze zpracovan√Ωch soubor≈Ø neexistuje, vytvo≈ô√≠m novou")
            self.processed_files_db.touch()
    
    def _add_to_processed(self, filename):
        """P≈ôid√° soubor do datab√°ze zpracovan√Ωch"""
        if filename not in self.processed_files:
            self.processed_files.add(filename)
            try:
                with open(self.processed_files_db, 'a', encoding='utf-8') as f:
                    f.write(f"{filename}\n")
                logger.info(f"‚úÖ Zaevidov√°n: {filename}")
            except Exception as e:
                logger.error(f"‚ùå Chyba z√°pisu do datab√°ze: {e}")

    def create_spreadsheet(self, title="OCR V√Ωsledky"):
        """Vytvo≈ô√≠ nov√Ω Google Sheets dokument"""
        try:
            spreadsheet = {
                'properties': {
                    'title': title
                },
                'sheets': [{
                    'properties': {
                        'title': 'OCR Data'
                    }
                }]
            }
            
            result = self.service.spreadsheets().create(body=spreadsheet).execute()
            self.spreadsheet_id = result['spreadsheetId']
            
            logger.info(f"‚úÖ Vytvo≈ôen Google Sheets: {result['properties']['title']}")
            logger.info(f"üìä Spreadsheet ID: {self.spreadsheet_id}")
            logger.info(f"üîó URL: https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}")
            
            return self.spreadsheet_id
            
        except HttpError as error:
            logger.error(f"‚ùå Chyba vytv√°≈ôen√≠ Sheets: {error}")
            return None

    def upload_csv_data(self, csv_file_path, sheet_name='Sheet1'):
        """Nahraje data z CSV do Google Sheets"""
        try:
            # Naƒçten√≠ CSV dat
            data = []
            with open(csv_file_path, 'r', encoding='utf-8') as csvfile:
                csv_reader = csv.reader(csvfile)
                for row in csv_reader:
                    data.append(row)
            
            if not data:
                logger.error("CSV soubor je pr√°zdn√Ω")
                return False
            
            # P≈ô√≠prava dat pro Google Sheets API
            body = {
                'values': data
            }
            
            result = self.service.spreadsheets().values().update(
                spreadsheetId=self.spreadsheet_id,
                range=f"{sheet_name}!A1",
                valueInputOption='RAW',
                body=body
            ).execute()
            
            logger.info(f"‚úÖ Nahr√°no {len(data)} ≈ô√°dk≈Ø do Google Sheets")
            logger.info(f"üìä Aktualizov√°no bunƒõk: {result.get('updatedCells')}")
            
            return True
            
        except Exception as error:
            logger.error(f"‚ùå Chyba nahr√°v√°n√≠ CSV: {error}")
            return False

    def upload_azure_json_data(self, json_dir='data/output', sheet_name='Sheet1'):
        """Nahraje jen specifick√© sloupce z Azure JSON dat s kontrolou duplik√°t≈Ø"""
        try:
            # Naƒçten√≠ JSON soubor≈Ø
            json_dir = Path(json_dir)
            json_files = list(json_dir.glob("*_analysis.json"))
            
            if not json_files:
                logger.error(f"≈Ω√°dn√© JSON soubory nenalezeny v {json_dir}")
                return False
            
            # Definice po≈æadovan√Ωch sloupc≈Ø (v po≈ôad√≠ jak chce≈°)
            required_fields = [
                "Typ kotle",
                "v√Ωrobn√≠ ƒç√≠slo kotle", 
                "prodejce kotle",
                "adresa prodejce",
                "kupuj√≠c√≠ kotle jmeno",
                "adresa z√°kazn√≠ka",
                "datum uveden√≠ do provozu",
                "ƒç√≠slo opr√°vnƒõn√≠",
                "regul√°tor",
                "adresa zakaznika doplneni"
            ]
            
            # Kontrola duplik√°t≈Ø a t≈ô√≠dƒõn√≠ soubor≈Ø
            new_files = []
            duplicate_files = []
            
            for json_file in json_files:
                filename = json_file.name
                if filename in self.processed_files:
                    duplicate_files.append(filename)
                    logger.warning(f"‚ö†Ô∏è DUPLIK√ÅT: {filename} (u≈æ byl zpracov√°n)")
                else:
                    new_files.append(json_file)
            
            # Zobrazen√≠ statistik
            logger.info(f"üìä KONTROLA DUPLIK√ÅT≈Æ:")
            logger.info(f"  Celkem soubor≈Ø: {len(json_files)}")
            logger.info(f"  Nov√Ωch k nahr√°n√≠: {len(new_files)}")
            logger.info(f"  Duplik√°t≈Ø p≈ôeskoƒçeno: {len(duplicate_files)}")
            
            # Z√°znam do log souboru pro zpƒõtnou kontrolu
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            log_entry = f"\n=== {timestamp} ===\n"
            log_entry += f"Celkem soubor≈Ø: {len(json_files)}\n"
            log_entry += f"Nov√Ωch k nahr√°n√≠: {len(new_files)}\n"
            log_entry += f"Duplik√°t≈Ø p≈ôeskoƒçeno: {len(duplicate_files)}\n"
            
            if duplicate_files:
                logger.warning(f"üö´ DUPLIK√ÅTY NEBUDOU NAHR√ÅNY:")
                log_entry += "DUPLIK√ÅTY:\n"
                for dup in duplicate_files:
                    logger.warning(f"  - {dup}")
                    log_entry += f"  - {dup}\n"
            
            if new_files:
                log_entry += "NOV√â SOUBORY:\n"
                for new_file in new_files:
                    log_entry += f"  + {new_file.name}\n"
            
            # Ulo≈æen√≠ do log souboru
            try:
                with open(self.duplicates_log, 'a', encoding='utf-8') as f:
                    f.write(log_entry)
                logger.info(f"üìù Z√°znam ulo≈æen do: {self.duplicates_log}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Chyba z√°pisu do logu: {e}")
            
            if not new_files:
                logger.info("‚úÖ ≈Ω√°dn√© nov√© soubory k nahr√°n√≠")
                return True
            
            # Naƒçten√≠ pouze nov√Ωch JSON dat
            json_data = []
            for json_file in new_files:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    json_data.append(data)
            
            logger.info(f"üìÑ Nahr√°v√°m {len(json_data)} nov√Ωch soubor≈Ø do Google Sheets")
            
            # Vytvo≈ôen√≠ hlaviƒçky - n√°zev souboru + po≈æadovan√© sloupce
            headers = ["nazev_souboru"] + required_fields
            
            # Vytvo≈ôen√≠ ≈ô√°dk≈Ø dat
            rows = [headers]  # Hlaviƒçka
            
            for data in json_data:
                row = []
                
                # N√°zev souboru jako prvn√≠
                row.append(data.get("source_file", ""))
                
                # Data z Azure extracted_fields
                extracted_fields = data.get("extracted_fields", {})
                
                # Pro ka≈æd√Ω po≈æadovan√Ω sloupec
                for field_name in required_fields:
                    value = extracted_fields.get(field_name, "")
                    row.append(value)
                
                rows.append(row)
            
            # Nahr√°n√≠ dat do Google Sheets
            body = {'values': rows}
            
            result = self.service.spreadsheets().values().update(
                spreadsheetId=self.spreadsheet_id,
                range="A1",
                valueInputOption='RAW',
                body=body
            ).execute()
            
            logger.info(f"‚úÖ Nahr√°no {len(rows)} ≈ô√°dk≈Ø do Google Sheets")
            logger.info(f"üìä Aktualizov√°no bunƒõk: {result.get('updatedCells')}")
            
            # Zaevidov√°n√≠ nov√Ωch soubor≈Ø do datab√°ze
            for json_file in new_files:
                self._add_to_processed(json_file.name)
            
            logger.info(f"üìã Zaevidov√°no {len(new_files)} nov√Ωch soubor≈Ø do datab√°ze")
            
            return True
            
        except Exception as error:
            logger.error(f"‚ùå Chyba nahr√°v√°n√≠ JSON dat: {error}")
            return False
    


def main():
    """Hlavn√≠ funkce pro nahr√°n√≠ OCR dat do Google Sheets"""
    logger.info("üöÄ Spou≈°t√≠m Google Sheets nahr√°v√°n√≠...")
    
    # Inicializace klienta
    client = GoogleSheetsClient()
    
    if not client.service:
        logger.error("‚ùå Nepoda≈ôilo se p≈ôipojit k Google Sheets API")
        logger.info("\nüìã POSTUP NASTAVEN√ç:")
        logger.info("1. Jdƒõte do Google Cloud Console")
        logger.info("2. Vytvo≈ôte Service Account")
        logger.info("3. St√°hnƒõte JSON kl√≠ƒç jako 'google-credentials.json'")
        logger.info("4. Um√≠stƒõte soubor do t√©to slo≈æky")
        return
    
    # Pou≈æit√≠ existuj√≠c√≠ho spreadsheetu m√≠sto vytv√°≈ôen√≠ nov√©ho
    client.spreadsheet_id = "129XnRNQytuHbvSE3NEa6evVdzlFGDjCRwKxXG58sZfA"
    logger.info(f"‚úÖ Pou≈æ√≠v√°m existuj√≠c√≠ spreadsheet: {client.spreadsheet_id}")
    
    # Nahr√°n√≠ Azure JSON dat p≈ô√≠mo s p≈Øvodn√≠mi n√°zvy pol√≠
    success = client.upload_azure_json_data(json_dir='data/output', sheet_name='um√≠stƒõn√≠ kotl≈Ø')
    
    if success:
        logger.info("\nüéâ √öSPƒöCH! Data nahr√°na do Google Sheets")
        logger.info(f"üîó Otev≈ôete: https://docs.google.com/spreadsheets/d/{client.spreadsheet_id}")
        

        
    else:
        logger.error("‚ùå Nepoda≈ôilo se nahr√°t data")

if __name__ == "__main__":
    main() 